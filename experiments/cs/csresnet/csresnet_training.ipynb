{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"csresnet_training.ipynb","provenance":[],"collapsed_sections":["tt_tbdObZFRi","MTpANeapZQnp"],"toc_visible":true,"authorship_tag":"ABX9TyNYAvlQ+1gpEx0QgUV5v1Me"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iBTMHdv4Ycvp"},"source":["# General Setup"]},{"cell_type":"markdown","metadata":{"id":"A989IoBQWQOT"},"source":["Install CR-VISION Package"]},{"cell_type":"code","metadata":{"id":"8O2Y7HSk5kGj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619292148816,"user_tz":-330,"elapsed":18368,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"1f3850a1-0f77-4ad7-8ec9-fd7fc1615956"},"source":["!python -m pip install --quiet git+https://github.com/carnotresearch/cr-vision.git\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.3MB 19.2MB/s \n","\u001b[K     |████████████████████████████████| 204kB 54.7MB/s \n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[K     |████████████████████████████████| 9.2MB 50.2MB/s \n","\u001b[K     |████████████████████████████████| 563kB 57.1MB/s \n","\u001b[K     |████████████████████████████████| 2.8MB 49.2MB/s \n","\u001b[K     |████████████████████████████████| 122kB 58.9MB/s \n","\u001b[K     |████████████████████████████████| 102kB 14.2MB/s \n","\u001b[K     |████████████████████████████████| 92kB 13.0MB/s \n","\u001b[K     |████████████████████████████████| 92kB 13.4MB/s \n","\u001b[?25h  Building wheel for cr-vision (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: sphinx 3.5.4 has requirement docutils<0.17,>=0.12, but you'll have docutils 0.17 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: sphinx-rtd-theme 0.5.2 has requirement docutils<0.17, but you'll have docutils 0.17 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9fx1NUh2WWfn"},"source":["Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXtIxS745xD2","executionInfo":{"status":"ok","timestamp":1619292176989,"user_tz":-330,"elapsed":26869,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"83817949-2a7b-41f6-957a-0a98893e2342"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d3cAXb-TWg1X"},"source":["Copy  and Unzip Training and Validation Images"]},{"cell_type":"code","metadata":{"id":"fOKzco1f6kUt","executionInfo":{"status":"ok","timestamp":1619292190271,"user_tz":-330,"elapsed":10629,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["!cp  /content/drive/MyDrive/datasets/birds/birds_subset_5000/training.zip ."],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"RacRNNtP_NJ5","executionInfo":{"status":"ok","timestamp":1619292195765,"user_tz":-330,"elapsed":3148,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["!unzip -q training.zip"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5S6UbBvY4N9p","executionInfo":{"status":"ok","timestamp":1619292206524,"user_tz":-330,"elapsed":5694,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["!cp  /content/drive/MyDrive/datasets/birds/birds_subset_5000/validation.zip ."],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"84r-BGCV4Q5g","executionInfo":{"status":"ok","timestamp":1619292210429,"user_tz":-330,"elapsed":1595,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["!unzip -q validation.zip"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrucBHxbW51a"},"source":["Copy  driver code for the experiment setup"]},{"cell_type":"code","metadata":{"id":"N07_cWr9_xvo","executionInfo":{"status":"ok","timestamp":1619294054651,"user_tz":-330,"elapsed":1770,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["!cp /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/csresnet.py ."],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U1CwmjL4XBG-"},"source":["Import essential packages\n","\n"]},{"cell_type":"code","metadata":{"id":"ajf4gQaOXFh0","executionInfo":{"status":"ok","timestamp":1619292217447,"user_tz":-330,"elapsed":1293,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["from pathlib import Path\n","import pandas as pd"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYdFa_AGXL9J"},"source":["Import utilities from CR-Vision package"]},{"cell_type":"code","metadata":{"id":"j_NZHRK1_1_X","executionInfo":{"status":"ok","timestamp":1619292224649,"user_tz":-330,"elapsed":4278,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["\n","from cr.vision.io import images_from_dir\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CKBc8fgvXRPg"},"source":["Import driver module for the experiment\n","\n"]},{"cell_type":"code","metadata":{"id":"HhmTj_FcWKDv","executionInfo":{"status":"ok","timestamp":1619292229813,"user_tz":-330,"elapsed":3519,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["import csresnet"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-u6JLheoYlWb"},"source":["# Auto Encoder Model Preparation"]},{"cell_type":"markdown","metadata":{"id":"1f9b8xX7X2Me"},"source":["Specify model definition parameters"]},{"cell_type":"code","metadata":{"id":"UULpz0MG1iA2","executionInfo":{"status":"ok","timestamp":1619292233213,"user_tz":-330,"elapsed":1709,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["patch_size = 24\n","stride_size = 16\n","compression_ratio = 64\n","num_res_blocks=2\n","num_res_channels=32\n","input_shape  = (256, 256, 3)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pOzyqp3rYFf3"},"source":["Build autoencoder model"]},{"cell_type":"code","metadata":{"id":"r5J8_WzjhheO","executionInfo":{"status":"ok","timestamp":1619292250244,"user_tz":-330,"elapsed":8443,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["models = csresnet.build_models(input_shape,\n","    patch_size=patch_size,\n","    stride_size=stride_size,\n","    num_res_blocks=num_res_blocks,\n","    num_res_channels=num_res_channels,\n","    compression_ratio=compression_ratio)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvCp9F0t1rs8","executionInfo":{"status":"ok","timestamp":1619292255209,"user_tz":-330,"elapsed":1946,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"6afb7a1d-949d-4544-e437-94b72063e084"},"source":["autoencoder = models.autoencoder\n","autoencoder.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"CSResNet_Autoencoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input (InputLayer)           [(None, 256, 256, 3)]     0         \n","_________________________________________________________________\n","CSResNet_Encoder (Functional (None, 16, 16, 12)        20748     \n","_________________________________________________________________\n","CSResNet_Decoder (Functional (None, 256, 256, 3)       240579    \n","=================================================================\n","Total params: 261,327\n","Trainable params: 261,327\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8CzkWax1vf0","executionInfo":{"status":"ok","timestamp":1619292260196,"user_tz":-330,"elapsed":2423,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"085cc4ed-69f5-4b54-8b5a-2a426aa1696d"},"source":["encoder = models.encoder\n","encoder.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"CSResNet_Encoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input (InputLayer)           [(None, 256, 256, 3)]     0         \n","_________________________________________________________________\n","sensor (Conv2D)              (None, 16, 16, 12)        20748     \n","=================================================================\n","Total params: 20,748\n","Trainable params: 20,748\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUT0YK0q12Po","executionInfo":{"status":"ok","timestamp":1619292264097,"user_tz":-330,"elapsed":1859,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"fc33d7e5-7970-47aa-c36d-f5379dd4110e"},"source":["decoder = models.decoder\n","decoder.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"CSResNet_Decoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoded_input (InputLayer)      [(None, 16, 16, 12)] 0                                            \n","__________________________________________________________________________________________________\n","initial (Conv2DTranspose)       (None, 256, 256, 32) 221216      encoded_input[0][0]              \n","__________________________________________________________________________________________________\n","residual-1 (Conv2D)             (None, 256, 256, 32) 9248        initial[0][0]                    \n","__________________________________________________________________________________________________\n","add-1 (Add)                     (None, 256, 256, 32) 0           initial[0][0]                    \n","                                                                 residual-1[0][0]                 \n","__________________________________________________________________________________________________\n","residual-2 (Conv2D)             (None, 256, 256, 32) 9248        add-1[0][0]                      \n","__________________________________________________________________________________________________\n","add-2 (Add)                     (None, 256, 256, 32) 0           add-1[0][0]                      \n","                                                                 residual-2[0][0]                 \n","__________________________________________________________________________________________________\n","final (Conv2D)                  (None, 256, 256, 3)  867         add-2[0][0]                      \n","__________________________________________________________________________________________________\n","final_relu (ReLU)               (None, 256, 256, 3)  0           final[0][0]                      \n","==================================================================================================\n","Total params: 240,579\n","Trainable params: 240,579\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KWprAHm7YX86"},"source":["Compile model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFwItu7JiXjA","executionInfo":{"status":"ok","timestamp":1619292288966,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"b3c32f91-a403-4414-8374-7d5c1fe21443"},"source":["csresnet.compile_model(autoencoder)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Compiling model for training.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.engine.functional.Functional at 0x7f0ff01bad10>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"hq8Y9RMrY5g2"},"source":["Add callbacks"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVwmk-44icqw","executionInfo":{"status":"ok","timestamp":1619292295842,"user_tz":-330,"elapsed":1802,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"ecf52f30-7cac-40fa-ac6f-034fc45bfbe7"},"source":["callbacks = csresnet.build_callbacks()\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Preparing callbacks for model training.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tt_tbdObZFRi"},"source":["# Training and validation data"]},{"cell_type":"markdown","metadata":{"id":"w-vZdPgIXXct"},"source":["Load training and validation images"]},{"cell_type":"code","metadata":{"id":"yg28b22B_dSz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619292311996,"user_tz":-330,"elapsed":8433,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"616904c4-fe5a-4f83-f76a-4ac7e5817c40"},"source":["rootdir = Path('.')\n","training_set = images_from_dir(rootdir / 'training', size=1200)\n","validation_set = images_from_dir(rootdir / 'validation', size=400)\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["training/025.Pelagic_Cormorant_Pelagic_Cormorant_0022_23802.jpg, (375, 500)\n","shape after conversion (375, 500, 3)\n","training/063.Ivory_Gull_Ivory_Gull_0040_49180.jpg, (326, 500)\n","shape after conversion (326, 500, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ah4ky5fs4rM1","executionInfo":{"status":"ok","timestamp":1619292317969,"user_tz":-330,"elapsed":1497,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"47eb1998-14a6-45c8-d0a8-60fcd916d79d"},"source":["print(f\"training set: {training_set.shape}\")\n","print(f\"validation set: {validation_set.shape}\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["training set: (1200, 256, 256, 3)\n","validation set: (400, 256, 256, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wKoKCMDEZLEk"},"source":["# Training setup"]},{"cell_type":"markdown","metadata":{"id":"kCXkQh1PXi0Y"},"source":["Specify training paramters"]},{"cell_type":"code","metadata":{"id":"N0z-uZjt1RTl","executionInfo":{"status":"ok","timestamp":1619292322001,"user_tz":-330,"elapsed":967,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["batch_size = 32\n","epochs=50\n","n_train = training_set.shape[0]\n","steps_per_epoch = n_train // batch_size"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uh2G7S7mXcfh"},"source":["Prepare training data augmentation generator"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acAZHmwQhLP-","executionInfo":{"status":"ok","timestamp":1619292353692,"user_tz":-330,"elapsed":28822,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"9be9733c-4628-4d1a-ac37-760afdc7c59a"},"source":["train_gen = csresnet.augment_training_set(training_set, batch_size = batch_size)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Preparing augmented training set generator.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MTpANeapZQnp"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kn2NfTpKifNd","executionInfo":{"status":"ok","timestamp":1619293873447,"user_tz":-330,"elapsed":1512590,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"9b2f6566-f7d1-4885-c980-98517908db68"},"source":["history = csresnet.fit_model(autoencoder, train_gen,\n","    validation_set, callbacks,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=epochs)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Initiating model training for 50 epochs.\n","<zip object at 0x7f0ff01580a0>\n","37 50\n","(400, 256, 256, 3)\n","Epoch 1/50\n","37/37 [==============================] - 64s 836ms/step - loss: 0.0663 - val_loss: 0.0190\n","\n","Epoch 00001: val_loss improved from inf to 0.01900, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 2/50\n","37/37 [==============================] - 30s 810ms/step - loss: 0.0166 - val_loss: 0.0120\n","\n","Epoch 00002: val_loss improved from 0.01900 to 0.01198, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 3/50\n","37/37 [==============================] - 29s 802ms/step - loss: 0.0106 - val_loss: 0.0093\n","\n","Epoch 00003: val_loss improved from 0.01198 to 0.00934, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 4/50\n","37/37 [==============================] - 29s 802ms/step - loss: 0.0085 - val_loss: 0.0083\n","\n","Epoch 00004: val_loss improved from 0.00934 to 0.00831, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 5/50\n","37/37 [==============================] - 30s 828ms/step - loss: 0.0077 - val_loss: 0.0074\n","\n","Epoch 00005: val_loss improved from 0.00831 to 0.00738, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 6/50\n","37/37 [==============================] - 30s 816ms/step - loss: 0.0067 - val_loss: 0.0068\n","\n","Epoch 00006: val_loss improved from 0.00738 to 0.00677, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 7/50\n","37/37 [==============================] - 29s 802ms/step - loss: 0.0062 - val_loss: 0.0064\n","\n","Epoch 00007: val_loss improved from 0.00677 to 0.00643, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 8/50\n","37/37 [==============================] - 29s 802ms/step - loss: 0.0056 - val_loss: 0.0062\n","\n","Epoch 00008: val_loss improved from 0.00643 to 0.00625, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 9/50\n","37/37 [==============================] - 29s 797ms/step - loss: 0.0056 - val_loss: 0.0060\n","\n","Epoch 00009: val_loss improved from 0.00625 to 0.00600, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 10/50\n","37/37 [==============================] - 29s 798ms/step - loss: 0.0052 - val_loss: 0.0059\n","\n","Epoch 00010: val_loss improved from 0.00600 to 0.00590, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 11/50\n","37/37 [==============================] - 29s 805ms/step - loss: 0.0053 - val_loss: 0.0059\n","\n","Epoch 00011: val_loss improved from 0.00590 to 0.00587, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 12/50\n","37/37 [==============================] - 29s 805ms/step - loss: 0.0050 - val_loss: 0.0059\n","\n","Epoch 00012: val_loss did not improve from 0.00587\n","Epoch 13/50\n","37/37 [==============================] - 29s 802ms/step - loss: 0.0049 - val_loss: 0.0056\n","\n","Epoch 00013: val_loss improved from 0.00587 to 0.00558, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 14/50\n","37/37 [==============================] - 29s 794ms/step - loss: 0.0047 - val_loss: 0.0056\n","\n","Epoch 00014: val_loss did not improve from 0.00558\n","Epoch 15/50\n","37/37 [==============================] - 29s 796ms/step - loss: 0.0048 - val_loss: 0.0064\n","\n","Epoch 00015: val_loss did not improve from 0.00558\n","Epoch 16/50\n","37/37 [==============================] - 29s 807ms/step - loss: 0.0048 - val_loss: 0.0054\n","\n","Epoch 00016: val_loss improved from 0.00558 to 0.00545, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 17/50\n","37/37 [==============================] - 29s 804ms/step - loss: 0.0045 - val_loss: 0.0053\n","\n","Epoch 00017: val_loss improved from 0.00545 to 0.00535, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 18/50\n","37/37 [==============================] - 29s 803ms/step - loss: 0.0048 - val_loss: 0.0059\n","\n","Epoch 00018: val_loss did not improve from 0.00535\n","Epoch 19/50\n","37/37 [==============================] - 29s 804ms/step - loss: 0.0049 - val_loss: 0.0054\n","\n","Epoch 00019: val_loss did not improve from 0.00535\n","Epoch 20/50\n","37/37 [==============================] - 29s 807ms/step - loss: 0.0047 - val_loss: 0.0056\n","\n","Epoch 00020: val_loss did not improve from 0.00535\n","Epoch 21/50\n","37/37 [==============================] - 29s 810ms/step - loss: 0.0043 - val_loss: 0.0052\n","\n","Epoch 00021: val_loss improved from 0.00535 to 0.00518, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 22/50\n","37/37 [==============================] - 29s 811ms/step - loss: 0.0043 - val_loss: 0.0051\n","\n","Epoch 00022: val_loss improved from 0.00518 to 0.00513, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 23/50\n","37/37 [==============================] - 29s 802ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 00023: val_loss improved from 0.00513 to 0.00510, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 24/50\n","37/37 [==============================] - 29s 805ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 00024: val_loss did not improve from 0.00510\n","Epoch 25/50\n","37/37 [==============================] - 29s 805ms/step - loss: 0.0041 - val_loss: 0.0052\n","\n","Epoch 00025: val_loss did not improve from 0.00510\n","Epoch 26/50\n","37/37 [==============================] - 29s 801ms/step - loss: 0.0042 - val_loss: 0.0050\n","\n","Epoch 00026: val_loss improved from 0.00510 to 0.00503, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 27/50\n","37/37 [==============================] - 30s 815ms/step - loss: 0.0040 - val_loss: 0.0051\n","\n","Epoch 00027: val_loss did not improve from 0.00503\n","Epoch 28/50\n","37/37 [==============================] - 29s 807ms/step - loss: 0.0040 - val_loss: 0.0051\n","\n","Epoch 00028: val_loss did not improve from 0.00503\n","Epoch 29/50\n","37/37 [==============================] - 29s 807ms/step - loss: 0.0043 - val_loss: 0.0050\n","\n","Epoch 00029: val_loss improved from 0.00503 to 0.00500, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 30/50\n","37/37 [==============================] - 29s 810ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 00030: val_loss improved from 0.00500 to 0.00492, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 31/50\n","37/37 [==============================] - 29s 807ms/step - loss: 0.0038 - val_loss: 0.0050\n","\n","Epoch 00031: val_loss did not improve from 0.00492\n","Epoch 32/50\n","37/37 [==============================] - 29s 808ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 00032: val_loss improved from 0.00492 to 0.00487, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 33/50\n","37/37 [==============================] - 29s 807ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 00033: val_loss did not improve from 0.00487\n","Epoch 34/50\n","37/37 [==============================] - 29s 803ms/step - loss: 0.0038 - val_loss: 0.0050\n","\n","Epoch 00034: val_loss did not improve from 0.00487\n","Epoch 35/50\n","37/37 [==============================] - 29s 803ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 00035: val_loss improved from 0.00487 to 0.00483, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 36/50\n","37/37 [==============================] - 29s 800ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 00036: val_loss did not improve from 0.00483\n","Epoch 37/50\n","37/37 [==============================] - 29s 809ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 00037: val_loss improved from 0.00483 to 0.00479, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 38/50\n","37/37 [==============================] - 29s 809ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 00038: val_loss did not improve from 0.00479\n","Epoch 39/50\n","37/37 [==============================] - 30s 818ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 00039: val_loss did not improve from 0.00479\n","Epoch 40/50\n","37/37 [==============================] - 30s 819ms/step - loss: 0.0039 - val_loss: 0.0050\n","\n","Epoch 00040: val_loss did not improve from 0.00479\n","Epoch 41/50\n","37/37 [==============================] - 30s 815ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 00041: val_loss did not improve from 0.00479\n","Epoch 42/50\n","37/37 [==============================] - 29s 811ms/step - loss: 0.0037 - val_loss: 0.0053\n","\n","Epoch 00042: val_loss did not improve from 0.00479\n","Epoch 43/50\n","37/37 [==============================] - 29s 808ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 00043: val_loss did not improve from 0.00479\n","Epoch 44/50\n","37/37 [==============================] - 29s 811ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 00044: val_loss improved from 0.00479 to 0.00476, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 45/50\n","37/37 [==============================] - 29s 808ms/step - loss: 0.0036 - val_loss: 0.0047\n","\n","Epoch 00045: val_loss improved from 0.00476 to 0.00469, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 46/50\n","37/37 [==============================] - 29s 812ms/step - loss: 0.0034 - val_loss: 0.0047\n","\n","Epoch 00046: val_loss improved from 0.00469 to 0.00468, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 47/50\n","37/37 [==============================] - 30s 813ms/step - loss: 0.0035 - val_loss: 0.0047\n","\n","Epoch 00047: val_loss did not improve from 0.00468\n","Epoch 48/50\n","37/37 [==============================] - 30s 815ms/step - loss: 0.0040 - val_loss: 0.0050\n","\n","Epoch 00048: val_loss did not improve from 0.00468\n","Epoch 49/50\n","37/37 [==============================] - 29s 811ms/step - loss: 0.0036 - val_loss: 0.0047\n","\n","Epoch 00049: val_loss improved from 0.00468 to 0.00466, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n","Epoch 50/50\n","37/37 [==============================] - 29s 809ms/step - loss: 0.0036 - val_loss: 0.0047\n","\n","Epoch 00050: val_loss improved from 0.00466 to 0.00466, saving model to /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/checkpoint.hdf5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J8qCQ8MWZR9q"},"source":["# Saving of trained model and training history"]},{"cell_type":"code","metadata":{"id":"0j3tCASQincV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619294122936,"user_tz":-330,"elapsed":3189,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"91212e6a-f7a2-48ef-d182-b9497978f150"},"source":["csresnet.save_model(models.autoencoder, csresnet.form_model_name('autoencoder', patch_size, stride_size, num_res_blocks, num_res_channels, compression_ratio))\n","csresnet.save_model(models.encoder, csresnet.form_model_name('encoder', patch_size, stride_size, num_res_blocks, num_res_channels, compression_ratio))\n","csresnet.save_model(models.decoder, csresnet.form_model_name('decoder', patch_size, stride_size, num_res_blocks, num_res_channels, compression_ratio))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Saving autoencoder_p=24_s=16_b=2_c=32_cr=64 in tensorflow SavedModel format.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/saved_model_autoencoder_p=24_s=16_b=2_c=32_cr=64/assets\n","Saving encoder_p=24_s=16_b=2_c=32_cr=64 in tensorflow SavedModel format.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/saved_model_encoder_p=24_s=16_b=2_c=32_cr=64/assets\n","Saving decoder_p=24_s=16_b=2_c=32_cr=64 in tensorflow SavedModel format.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet/saved_model_decoder_p=24_s=16_b=2_c=32_cr=64/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SoXZjaVY8vge","executionInfo":{"status":"ok","timestamp":1619294181497,"user_tz":-330,"elapsed":984,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}},"outputId":"d5cf37a7-b318-4149-967e-0313ff05db4f"},"source":["name = csresnet.form_model_name('history', patch_size, stride_size, num_res_blocks, num_res_channels, compression_ratio)\n","history_file = f'{csresnet.GD_EXP_DIR}_{name}.json'\n","history_file"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/work/cr-vision/experiments/cs/csresnet_history_p=24_s=16_b=2_c=32_cr=64.json'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"RJiGa8_o9H0X","executionInfo":{"status":"ok","timestamp":1619294187086,"user_tz":-330,"elapsed":1110,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["hist_df = pd.DataFrame(history.history)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ndG6-ug9KaG","executionInfo":{"status":"ok","timestamp":1619294189871,"user_tz":-330,"elapsed":1065,"user":{"displayName":"Shailesh Kumar","photoUrl":"","userId":"17557417109418259401"}}},"source":["with open(history_file, mode='w') as f:\n","        hist_df.to_json(f)"],"execution_count":31,"outputs":[]}]}